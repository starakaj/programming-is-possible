# Gesture Recognition

## Authors
Sam Tarakajian for NYU IDM

DM-GY 6063

@starakaj

## Essential Questions
- What are the different ways of encoding gestural information for a computer?
- How can we extract useful data from that information?
- What kinds of systems can we drive with that data?

## Introduction
In addition to verbal communication, people also have a highly developed language of gestural communication. These gestures can be deliberate forms of person-to-person communication, like waving to say hello, or pointing to indicate a specific object in the distance. They can also communicate between people and objects, for example the gestures by which a violinist communicates with their instuments. Finally, human gestures might communicate something about their environment, in the sense that the swaying of subway passengers tells us something about the motion of the subway car.

Many computer libraries are designed for working with gestural information. In order to drive computer systems with a gesture, it must first be captured, and then analyzed to retrieve useful information. Cameras, depth sensors, accelerometers and position trackers are all used for gesture capture. Finally, there are several statistical and machine-learning tools that can pull useful information from captured gesture data.

In this class, we'll look at systems for data capture including webcam, depth camera, and Leap Motion. Next, we'll see how to use Wekinator to analyze captured data, and we'll map that data to some useful output.

### Target Audience / Prerequisite & Pre-Assessment
This module is part of DM-GY 6063, _Programming is the Art of the Possible_. This is a second semester creative coding course, designed for students who have a strong JavaScript foundation.

### Outcomes & Goals
- In this class we will use webcams, depth cameras, and motion trackers to capture gesture data.
- We will analyze that data and map it to some other process.
- Students will walk away with a deeper understanding of the technologies available for gestural analysis, as well as the challenges inherit in using that data.

### Pacing / Duration
TBD

## Materials Needed
To be decided, but as a point of departure:
- Hardware
    - Webcam
    - Depth Camera (Kinect)
    - Trackpad
    - Leap Motion
    - Drawing pad + pen
    - Bela.io
- Software
    - Max/MSP
    - Processing
    - Wekinator

### Exercises To Do Before Class
TBD, maybe there can be some reading on statistical gestural analysis? HMMs?

### Vocabulary 
* Gesture - Semiotic dynamic posture. Reconfiguration of a body, relative to its own reference frame or to the world around it, in a way that deliberately or incidentally conveys meaning. (provisional definition to be revisited).
* Features - Parameters of a model that best-explains a given data set. Please revisit this definiton as it's garbage.

## Exercise Descriptions
TBD

## Student Reflections, Takeaways & Next Steps
TBD

## Post Session
TBD

### References
TBD

### Implementation Guidance & Teaching Reflection  
TBD

***With thanks and acknowledgement, this is based on the template provided by [Eyebeam](https://github.com/eyebeam/curriculum/blob/master/TEMPLATE.md)***